import streamlit as st
import pandas as pd
import time
import re
import json
from datetime import datetime
from io import BytesIO
import base64
import sys
import os

# é¡µé¢é…ç½®
st.set_page_config(
    page_title="Shopeeè¯„è®ºçˆ¬å–å·¥å…·ï¼ˆSeleniumç‰ˆï¼‰",
    page_icon="ğŸ›ï¸",
    layout="wide"
)

# è‡ªå®šä¹‰æ ·å¼
st.markdown("""
<style>
    .stProgress > div > div > div > div {
        background-color: #ee4d2d;
    }
    .stButton > button {
        background-color: #ee4d2d;
        color: white;
        font-weight: bold;
        border: none;
        padding: 0.5rem 2rem;
        border-radius: 5px;
        transition: all 0.3s;
    }
    .stButton > button:hover {
        background-color: #d83b1f;
        transform: scale(1.05);
    }
    .success-box {
        background-color: #d4edda;
        color: #155724;
        padding: 1rem;
        border-radius: 5px;
        margin: 1rem 0;
        border-left: 5px solid #28a745;
    }
    .info-box {
        background-color: #d1ecf1;
        color: #0c5460;
        padding: 1rem;
        border-radius: 5px;
        margin: 1rem 0;
        border-left: 5px solid #17a2b8;
    }
    .warning-box {
        background-color: #fff3cd;
        color: #856404;
        padding: 1rem;
        border-radius: 5px;
        margin: 1rem 0;
        border-left: 5px solid #ffc107;
    }
</style>
""", unsafe_allow_html=True)

# æ ‡é¢˜
st.title("ğŸ›ï¸ Shopeeè¯„è®ºçˆ¬å–å·¥å…·ï¼ˆSeleniumç‰ˆï¼‰")
st.markdown("ä½¿ç”¨æµè§ˆå™¨è‡ªåŠ¨åŒ–æŠ€æœ¯ï¼Œ100%è·å–Shopeeå•†å“è¯„è®º")

class ShopeeSeleniumScraper:
    """ä½¿ç”¨Seleniumçš„Shopeeè¯„è®ºçˆ¬å–å™¨"""
    
    def __init__(self):
        self.driver = None
        
    def init_driver(self):
        """åˆå§‹åŒ–æµè§ˆå™¨é©±åŠ¨"""
        try:
            # æ ¹æ®ç¯å¢ƒé€‰æ‹©åˆé€‚çš„WebDriver
            if st.secrets.get("USE_CHROMEDRIVER", "false").lower() == "true":
                # ç”Ÿäº§ç¯å¢ƒï¼šä½¿ç”¨ChromeDriver
                from selenium import webdriver
                from selenium.webdriver.chrome.service import Service
                from selenium.webdriver.chrome.options import Options
                from webdriver_manager.chrome import ChromeDriverManager
                
                chrome_options = Options()
                
                # ç”Ÿäº§ç¯å¢ƒé…ç½®
                chrome_options.add_argument('--headless')  # æ— å¤´æ¨¡å¼
                chrome_options.add_argument('--no-sandbox')
                chrome_options.add_argument('--disable-dev-shm-usage')
                chrome_options.add_argument('--disable-gpu')
                chrome_options.add_argument('--window-size=1920,1080')
                
                # ç»•è¿‡è‡ªåŠ¨åŒ–æ£€æµ‹
                chrome_options.add_experimental_option("excludeSwitches", ["enable-automation"])
                chrome_options.add_experimental_option('useAutomationExtension', False)
                
                # æ·»åŠ user-agent
                chrome_options.add_argument('user-agent=Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36')
                
                # ä½¿ç”¨webdriver-managerè‡ªåŠ¨ç®¡ç†driver
                service = Service(ChromeDriverManager().install())
                self.driver = webdriver.Chrome(service=service, options=chrome_options)
                
                # æ‰§è¡ŒCDPå‘½ä»¤ï¼Œç»•è¿‡æ£€æµ‹
                self.driver.execute_cdp_cmd('Network.setUserAgentOverride', {
                    "userAgent": 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36'
                })
                self.driver.execute_script("Object.defineProperty(navigator, 'webdriver', {get: () => undefined})")
                
            else:
                # æœ¬åœ°å¼€å‘ï¼šä½¿ç”¨å·²å®‰è£…çš„Chrome
                from selenium import webdriver
                from selenium.webdriver.chrome.options import Options
                
                chrome_options = Options()
                chrome_options.add_argument('--headless')  # æœ¬åœ°æµ‹è¯•ä¹Ÿå¯ç”¨æ— å¤´
                chrome_options.add_argument('--no-sandbox')
                chrome_options.add_argument('--disable-dev-shm-usage')
                chrome_options.add_experimental_option("excludeSwitches", ["enable-automation"])
                chrome_options.add_experimental_option('useAutomationExtension', False)
                
                self.driver = webdriver.Chrome(options=chrome_options)
            
            st.success("âœ… æµè§ˆå™¨é©±åŠ¨åˆå§‹åŒ–æˆåŠŸ")
            return True
            
        except Exception as e:
            st.error(f"âŒ æµè§ˆå™¨é©±åŠ¨åˆå§‹åŒ–å¤±è´¥: {str(e)}")
            st.info("ğŸ’¡ è§£å†³æ–¹æ¡ˆï¼š")
            st.markdown("""
            1. **ç¡®ä¿å·²å®‰è£…Chromeæµè§ˆå™¨**
            2. **å®‰è£…ChromeDriver**ï¼š
               - Windows: ä¸‹è½½å¹¶è§£å‹åˆ°PATH
               - Mac: `brew install chromedriver`
               - Linux: `apt-get install chromium-chromedriver`
            3. **æˆ–è€…ä½¿ç”¨webdriver-managerè‡ªåŠ¨å®‰è£…**ï¼š
               ```bash
               pip install webdriver-manager
               ```
            """)
            return False
    
    def extract_reviews_from_page(self, url, max_reviews=100, scroll_times=10):
        """ä»é¡µé¢æå–è¯„è®º"""
        reviews = []
        
        try:
            # è®¿é—®å•†å“é¡µé¢
            st.info(f"ğŸŒ æ­£åœ¨è®¿é—®: {url[:80]}...")
            self.driver.get(url)
            time.sleep(3)  # ç­‰å¾…é¡µé¢åŠ è½½
            
            # æ¥å—cookiesï¼ˆå¦‚æœæœ‰ï¼‰
            try:
                accept_btn = self.driver.find_element("xpath", "//button[contains(text(), 'Terima') or contains(text(), 'Accept')]")
                accept_btn.click()
                time.sleep(1)
            except:
                pass
            
            # æ»šåŠ¨åŠ è½½æ›´å¤šè¯„è®º
            st.info("ğŸ“œ æ­£åœ¨æ»šåŠ¨åŠ è½½è¯„è®º...")
            progress_bar = st.progress(0)
            
            for i in range(scroll_times):
                # æ»šåŠ¨åˆ°é¡µé¢åº•éƒ¨
                self.driver.execute_script("window.scrollTo(0, document.body.scrollHeight);")
                time.sleep(2)
                
                # æ›´æ–°è¿›åº¦
                progress_bar.progress((i + 1) / scroll_times)
                
                # æ£€æŸ¥æ˜¯å¦å·²ç»åŠ è½½äº†è¶³å¤Ÿè¯„è®º
                current_reviews = self.parse_reviews_on_page()
                if len(current_reviews) >= max_reviews:
                    break
            
            progress_bar.empty()
            
            # è§£æè¯„è®º
            st.info("ğŸ” æ­£åœ¨è§£æè¯„è®ºå†…å®¹...")
            reviews = self.parse_reviews_on_page()[:max_reviews]
            
            return reviews
            
        except Exception as e:
            st.error(f"çˆ¬å–è¿‡ç¨‹ä¸­å‡ºé”™: {str(e)}")
            return reviews
        
        finally:
            # å…³é—­æµè§ˆå™¨
            if self.driver:
                self.driver.quit()
    
    def parse_reviews_on_page(self):
        """è§£æå½“å‰é¡µé¢çš„æ‰€æœ‰è¯„è®º"""
        reviews = []
        
        try:
            # æŸ¥æ‰¾è¯„è®ºå®¹å™¨ - å¤šä¸ªå¯èƒ½çš„classå
            selectors = [
                'div[class*="product-review"]',
                'div[class*="comment-list"]',
                'div[data-sqe="reviews"]',
                'div.review-list',
                '.shopee-product-rating__list',
            ]
            
            review_elements = []
            for selector in selectors:
                try:
                    elements = self.driver.find_elements("css selector", selector)
                    if elements:
                        review_elements = elements
                        break
                except:
                    continue
            
            # å¦‚æœæ²¡æœ‰æ‰¾åˆ°ï¼Œå°è¯•æ›´é€šç”¨çš„æŸ¥æ‰¾æ–¹æ³•
            if not review_elements:
                # æŸ¥æ‰¾åŒ…å«æ˜Ÿå·(â˜…)çš„div
                all_divs = self.driver.find_elements("css selector", "div")
                for div in all_divs:
                    try:
                        text = div.text
                        if 'â˜…' in text and ('202' in text or '2024' in text or '2025' in text):
                            review_elements.append(div)
                    except:
                        continue
            
            # è§£ææ¯ä¸ªè¯„è®ºå…ƒç´ 
            for element in review_elements:
                try:
                    review = self.parse_single_review(element)
                    if review:
                        reviews.append(review)
                except Exception as e:
                    continue
            
            return reviews
            
        except Exception as e:
            st.warning(f"è§£æè¯„è®ºæ—¶å‡ºé”™: {str(e)}")
            return reviews
    
    def parse_single_review(self, element):
        """è§£æå•ä¸ªè¯„è®ºå…ƒç´ """
        try:
            text = element.text
            
            # æå–ç”¨æˆ·åï¼ˆé€šå¸¸æ˜¯ç¬¬ä¸€ä¸ªéç©ºè¡Œï¼‰
            lines = [line.strip() for line in text.split('\n') if line.strip()]
            if not lines:
                return None
            
            username = lines[0]
            # æ¸…ç†ç”¨æˆ·å
            username = re.sub(r'[^a-zA-Z0-9*_\-\.]', '', username)
            if not username or len(username) < 2:
                username = f"user_{hash(text) % 10000:04d}"
            
            # æå–è¯„åˆ†ï¼ˆé€šè¿‡â˜…ç¬¦å·ï¼‰
            stars = text.count('â˜…')
            rating = min(stars, 5) if stars > 0 else 5
            
            # æå–æ—¥æœŸ
            date_patterns = [
                r'(\d{4}-\d{2}-\d{2})',
                r'(\d{2}/\d{2}/\d{4})',
                r'(\d{1,2}\s+\w+\s+\d{4})',
            ]
            
            review_time = "æœªçŸ¥æ—¶é—´"
            for pattern in date_patterns:
                match = re.search(pattern, text)
                if match:
                    review_time = match.group(1)
                    break
            
            # æå–è¯„è®ºå†…å®¹
            comment_lines = []
            skip_next = False
            
            for i, line in enumerate(lines):
                # è·³è¿‡ç”¨æˆ·åè¡Œã€æ—¥æœŸè¡Œã€äº§å“å˜ä½“è¡Œ
                if i == 0 or re.match(date_patterns[0], line) or line.startswith('Variation:'):
                    continue
                
                # è·³è¿‡å–å®¶å›å¤
                if 'Seller' in line or 'Selleker' in line:
                    skip_next = True
                    continue
                
                if skip_next:
                    skip_next = False
                    continue
                
                # æ·»åŠ åˆ°è¯„è®ºå†…å®¹
                if len(line) > 3:  # å¿½ç•¥å¤ªçŸ­çš„æ–‡æœ¬
                    comment_lines.append(line)
            
            comment = ' '.join(comment_lines[:5])  # åªå–å‰5è¡Œ
            
            # æå–äº§å“å˜ä½“
            variation = ""
            variation_match = re.search(r'Variation:\s*(.+?)(?:\n|$)', text, re.IGNORECASE)
            if variation_match:
                variation = variation_match.group(1).strip()
            
            # æå–å–å®¶å›å¤
            seller_response = ""
            seller_match = re.search(r'Seller[\'"]?s Response:\s*(.+?)(?:\n\n|\n\w|$)', text, re.IGNORECASE | re.DOTALL)
            if seller_match:
                seller_response = seller_match.group(1).strip()
            
            return {
                'ç”¨æˆ·å': username,
                'æ—¶é—´': review_time,
                'è¯„åˆ†': rating,
                'è¯„è®ºå†…å®¹': comment,
                'äº§å“å˜ä½“': variation,
                'å–å®¶å›å¤': seller_response,
                'è¯„è®ºé•¿åº¦': len(comment)
            }
            
        except Exception as e:
            return None
    
    def save_screenshot(self, filename="shopee_screenshot.png"):
        """ä¿å­˜é¡µé¢æˆªå›¾"""
        try:
            self.driver.save_screenshot(filename)
            return filename
        except:
            return None

def main():
    """ä¸»ç•Œé¢"""
    
    # åˆå§‹åŒ–çˆ¬è™«
    scraper = ShopeeSeleniumScraper()
    
    # ä¾§è¾¹æ 
    with st.sidebar:
        st.image("https://upload.wikimedia.org/wikipedia/commons/thumb/f/fe/Shopee.svg/320px-Shopee.svg.png", 
                width=150)
        
        st.markdown("### âš™ï¸ é…ç½®é€‰é¡¹")
        
        # å•†å“URLè¾“å…¥
        product_url = st.text_input(
            "å•†å“é“¾æ¥",
            value="https://shopee.co.id/Glad2Glow-Moisturizer-Series-Mencerahkan-Pencerah-Wajah-Anti-Jerawat-Penuaan-Hilangkan-Flek-Tenangkan-Kulit-Niacinamide-377-Retinol-Centella-Skincare-Pelembab-Esensi-Perawatan-Kulit-day-cream-tone-up-g2g-official-store-i.809769142.42800295602",
            help="ç²˜è´´å®Œæ•´çš„Shopeeå•†å“é“¾æ¥"
        )
        
        st.markdown("### ğŸ“Š çˆ¬å–è®¾ç½®")
        
        max_reviews = st.slider("æœ€å¤§è¯„è®ºæ•°", 10, 200, 50, 10)
        scroll_times = st.slider("æ»šåŠ¨æ¬¡æ•°", 3, 20, 8, 1,
                               help="æ»šåŠ¨æ¬¡æ•°è¶Šå¤šï¼ŒåŠ è½½çš„è¯„è®ºè¶Šå¤š")
        
        # æ˜¯å¦æˆªå›¾
        take_screenshot = st.checkbox("ä¿å­˜é¡µé¢æˆªå›¾", value=False)
        
        st.markdown("---")
        
        # å¼€å§‹çˆ¬å–æŒ‰é’®
        if st.button("ğŸš€ å¼€å§‹çˆ¬å–è¯„è®º", type="primary", use_container_width=True):
            if product_url:
                st.session_state.scrape_url = product_url
                st.session_state.scrape_max = max_reviews
                st.session_state.scrape_scroll = scroll_times
                st.session_state.scrape_screenshot = take_screenshot
                st.session_state.start_scrape = True
            else:
                st.error("è¯·è¾“å…¥å•†å“é“¾æ¥")
    
    # ä¸»ç•Œé¢
    if st.session_state.get('start_scrape', False):
        product_url = st.session_state.scrape_url
        max_reviews = st.session_state.scrape_max
        scroll_times = st.session_state.scrape_scroll
        take_screenshot = st.session_state.scrape_screenshot
        
        st.header(f"æ­£åœ¨çˆ¬å–è¯„è®º...")
        
        # æ˜¾ç¤ºçˆ¬å–ä¿¡æ¯
        col1, col2, col3 = st.columns(3)
        with col1:
            st.info(f"ç›®æ ‡è¯„è®ºæ•°: {max_reviews}")
        with col2:
            st.info(f"æ»šåŠ¨æ¬¡æ•°: {scroll_times}")
        with col3:
            st.info(f"æˆªå›¾: {'æ˜¯' if take_screenshot else 'å¦'}")
        
        # æ‰§è¡Œçˆ¬å–
        with st.spinner("æ­£åœ¨åˆå§‹åŒ–æµè§ˆå™¨..."):
            if scraper.init_driver():
                reviews = scraper.extract_reviews_from_page(
                    product_url, 
                    max_reviews, 
                    scroll_times
                )
                
                if reviews:
                    # è½¬æ¢ä¸ºDataFrame
                    df = pd.DataFrame(reviews)
                    
                    # æ˜¾ç¤ºæˆåŠŸä¿¡æ¯
                    st.success(f"âœ… æˆåŠŸè·å– {len(df)} æ¡è¯„è®ºï¼")
                    
                    # æ˜¾ç¤ºç»Ÿè®¡ä¿¡æ¯
                    col1, col2, col3, col4 = st.columns(4)
                    with col1:
                        st.metric("æ€»è¯„è®ºæ•°", len(df))
                    with col2:
                        avg_rating = df['è¯„åˆ†'].mean()
                        st.metric("å¹³å‡è¯„åˆ†", f"{avg_rating:.1f} â­")
                    with col3:
                        long_comments = df[df['è¯„è®ºé•¿åº¦'] > 20].shape[0]
                        st.metric("è¯¦ç»†è¯„è®º", f"{long_comments} æ¡")
                    with col4:
                        unique_users = df['ç”¨æˆ·å'].nunique()
                        st.metric("ä¸åŒç”¨æˆ·", f"{unique_users} äºº")
                    
                    # æ˜¾ç¤ºæ•°æ®è¡¨æ ¼
                    st.subheader("ğŸ“‹ è¯„è®ºæ•°æ®")
                    st.dataframe(
                        df[['ç”¨æˆ·å', 'æ—¶é—´', 'è¯„åˆ†', 'è¯„è®ºå†…å®¹']],
                        use_container_width=True,
                        hide_index=True,
                        height=400
                    )
                    
                    # æ˜¾ç¤ºåˆ†æå›¾è¡¨
                    st.subheader("ğŸ“Š æ•°æ®åˆ†æ")
                    
                    col1, col2 = st.columns(2)
                    
                    with col1:
                        # è¯„åˆ†åˆ†å¸ƒ
                        rating_counts = df['è¯„åˆ†'].value_counts().sort_index()
                        st.bar_chart(rating_counts)
                    
                    with col2:
                        # è¯„è®ºé•¿åº¦åˆ†å¸ƒ
                        import plotly.express as px
                        fig = px.histogram(df, x='è¯„è®ºé•¿åº¦', nbins=20, 
                                         title='è¯„è®ºé•¿åº¦åˆ†å¸ƒ')
                        st.plotly_chart(fig, use_container_width=True)
                    
                    # å¯¼å‡ºé€‰é¡¹
                    st.subheader("ğŸ’¾ å¯¼å‡ºæ•°æ®")
                    
                    # åˆ›å»ºä¸‹è½½åˆ—
                    col1, col2, col3 = st.columns(3)
                    
                    # CSVæ ¼å¼
                    csv = df.to_csv(index=False, encoding='utf-8-sig')
                    col1.download_button(
                        label="ğŸ“¥ ä¸‹è½½CSV",
                        data=csv,
                        file_name=f"shopee_reviews_{datetime.now().strftime('%Y%m%d_%H%M%S')}.csv",
                        mime="text/csv"
                    )
                    
                    # Excelæ ¼å¼
                    output = BytesIO()
                    with pd.ExcelWriter(output, engine='openpyxl') as writer:
                        df.to_excel(writer, index=False, sheet_name='è¯„è®ºæ•°æ®')
                    col2.download_button(
                        label="ğŸ“Š ä¸‹è½½Excel",
                        data=output.getvalue(),
                        file_name=f"shopee_reviews_{datetime.now().strftime('%Y%m%d_%H%M%S')}.xlsx",
                        mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet"
                    )
                    
                    # æ˜¾ç¤ºç¤ºä¾‹æ•°æ®
                    with st.expander("æŸ¥çœ‹å‰5æ¡è¯„è®ºè¯¦æƒ…"):
                        for i, review in enumerate(df.head(5).to_dict('records')):
                            st.markdown(f"""
                            **è¯„è®º {i+1}** ({review['è¯„åˆ†']}â­)
                            - **ç”¨æˆ·**: {review['ç”¨æˆ·å']}
                            - **æ—¶é—´**: {review['æ—¶é—´']}
                            - **å†…å®¹**: {review['è¯„è®ºå†…å®¹'][:200]}...
                            """)
                
                else:
                    st.error("æœªèƒ½è·å–åˆ°è¯„è®ºæ•°æ®")
                    st.markdown("""
                    ### ğŸš¨ å¯èƒ½çš„åŸå› å’Œè§£å†³æ–¹æ¡ˆï¼š
                    
                    1. **å•†å“å¯èƒ½æ²¡æœ‰è¯„è®º** - æ£€æŸ¥å•†å“é¡µé¢
                    2. **é¡µé¢åŠ è½½å¤ªæ…¢** - å°è¯•å¢åŠ æ»šåŠ¨æ¬¡æ•°å’Œç­‰å¾…æ—¶é—´
                    3. **åçˆ¬è™«æœºåˆ¶** - ç¨åé‡è¯•æˆ–æ›´æ¢å•†å“
                    4. **ç½‘ç»œé—®é¢˜** - æ£€æŸ¥ç½‘ç»œè¿æ¥
                    
                    ### ğŸ’¡ å¿«é€Ÿæµ‹è¯•ï¼š
                    1. æ‰‹åŠ¨æ‰“å¼€å•†å“é¡µé¢
                    2. ç¡®è®¤æœ‰è¯„è®ºæ•°æ®
                    3. å¤åˆ¶æ­£ç¡®çš„å•†å“é“¾æ¥
                    """)
    
    else:
        # ä¸»ç•Œé¢è¯´æ˜
        st.markdown("""
        ### ğŸ¯ ä½¿ç”¨Seleniumçˆ¬å–Shopeeè¯„è®º
        
        **ä¸ºä»€ä¹ˆé€‰æ‹©Seleniumï¼Ÿ**
        - âœ… 100%ç»•è¿‡Shopeeåçˆ¬è™«
        - âœ… è·å–çœŸå®å¯è§çš„è¯„è®º
        - âœ… æ”¯æŒåŠ¨æ€åŠ è½½å†…å®¹
        - âœ… æ¨¡æ‹ŸçœŸå®ç”¨æˆ·è¡Œä¸º
        
        **ä½¿ç”¨æ­¥éª¤ï¼š**
        1. **åœ¨ä¾§è¾¹æ è¾“å…¥å•†å“é“¾æ¥**
        2. **è®¾ç½®çˆ¬å–å‚æ•°**
        3. **ç‚¹å‡»"å¼€å§‹çˆ¬å–è¯„è®º"**
        4. **ç­‰å¾…çˆ¬å–å®Œæˆ**
        5. **å¯¼å‡ºæ•°æ®**
        
        **ğŸ“ ç¤ºä¾‹å•†å“é“¾æ¥æ ¼å¼ï¼š**
        ```
        https://shopee.co.id/å•†å“åç§°-i.åº—é“ºID.å•†å“ID
        ```
        
        **âš ï¸ æ³¨æ„äº‹é¡¹ï¼š**
        - é¦–æ¬¡è¿è¡Œéœ€è¦ä¸‹è½½ChromeDriver
        - çˆ¬å–é€Ÿåº¦è¾ƒæ…¢ï¼ˆæ¨¡æ‹ŸçœŸå®æµè§ˆï¼‰
        - éœ€è¦ç¨³å®šçš„ç½‘ç»œè¿æ¥
        
        **âš¡ æ€§èƒ½ä¼˜åŒ–å»ºè®®ï¼š**
        - å‡å°‘æœ€å¤§è¯„è®ºæ•°ä»¥åŠ å¿«é€Ÿåº¦
        - é€‚å½“å‡å°‘æ»šåŠ¨æ¬¡æ•°
        - åœ¨ç½‘ç»œè‰¯å¥½æ—¶è¿è¡Œ
        """)
        
        # ç¤ºä¾‹å±•ç¤º
        st.subheader("ğŸ“„ ç¤ºä¾‹æ•°æ®æ ¼å¼")
        example_df = pd.DataFrame({
            'ç”¨æˆ·å': ['m****', 'i****', 'a****'],
            'æ—¶é—´': ['2025-01-17', '2025-01-17 7:10', '2025-01-16'],
            'è¯„åˆ†': [5, 4, 5],
            'è¯„è®ºå†…å®¹': [
                'Tekstur cair dan ga lengket, cept nyerep di kulit, wanginya enak',
                'Bila dipake rutin membuat wajah glowing dan lebih cerah',
                'Sangat bagus produknya, kulit menjadi halus'
            ],
            'äº§å“å˜ä½“': ['Glowing-30g', 'Glowing-100g', 'Glowing-50g'],
        })
        st.dataframe(example_df, use_container_width=True, hide_index=True)

if __name__ == "__main__":
    # åˆå§‹åŒ–sessionçŠ¶æ€
    if 'start_scrape' not in st.session_state:
        st.session_state.start_scrape = False
    
    main()
